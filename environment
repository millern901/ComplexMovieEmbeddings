{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"environment","provenance":[],"collapsed_sections":["b4-UPtcEjmND","QetNfEa1jruM","t9k5jzVgjw92","czVu1NXVj0FW","jXbJ1wp-DNJe","rLhQmAwBzkoO","lV8kuvEJDaUT","11SDap2EC-ML","oBwA3VAv1hhi","s40cwKES1h0E","UeO_0KA01om3"],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1WqMF4sEVcJ6sw1nWtQmQbKz8NHZuA3o8","authorship_tag":"ABX9TyORbbv+PElR1V8rkmRydmJw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"K3FBU5CnrB4r","colab_type":"text"},"source":["# **Change Working Directory**"]},{"cell_type":"code","metadata":{"id":"8xKBHQSy4yO_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1599759537722,"user_tz":240,"elapsed":938,"user":{"displayName":"Nicholas Miller","photoUrl":"","userId":"10828150341597191663"}},"outputId":"807a6b4d-ff3b-4b2a-d0e4-45b88b45d65e"},"source":["cd drive/My\\ Drive/Undergraduate-Research/Embedding-Movies/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Undergraduate-Research/Embedding-Movies/Knowledge-Graph-Embeddings\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yrRZSiOyqmqB","colab_type":"code","colab":{}},"source":["# package imports \n","import numpy as np\n","import pandas as pd\n","import os \n","import json\n","import random\n","import math\n","import logging\n","import tqdm\n","import torch\n","import torch.nn as nn\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4-UPtcEjmND","colab_type":"text"},"source":["# **Preprocess**"]},{"cell_type":"markdown","metadata":{"id":"QetNfEa1jruM","colab_type":"text"},"source":["## **DBpedia to Knowledge Graph**"]},{"cell_type":"code","metadata":{"id":"NS_oIFga5BUv","colab_type":"code","colab":{}},"source":["!chmod 755 data/source/dbpedia_connector.py\n","!python data/source/dbpedia_connector.py\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t9k5jzVgjw92","colab_type":"text"},"source":["## **Ratings**"]},{"cell_type":"code","metadata":{"id":"amc3xsdbkMjl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":82},"executionInfo":{"status":"ok","timestamp":1599759563340,"user_tz":240,"elapsed":26544,"user":{"displayName":"Nicholas Miller","photoUrl":"","userId":"10828150341597191663"}},"outputId":"f47cd2c4-2bce-4e98-8abc-224fd8479f28"},"source":["!python data/preprocess_ratings.py --data_path data/ --dataset ml1m --filter_unseen --frequency 10\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-10 17:39:00,008 - root - INFO - Filtering infrequent users and items (<=10) ...\n","2020-09-10 17:39:11,404 - root - INFO - Beginning the splitting of data into 70.00% training, 20.00% testing, 10.00% validation\n","2020-09-10 17:39:12,542 - root - INFO - There are: 664195 train, 189763 test and 94999 validate examples!\n","2020-09-10 17:39:12,542 - root - INFO - There are: 948957 interactions with 6040 users and 3227 movies!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"czVu1NXVj0FW","colab_type":"text"},"source":["## **Knowledge Graph**"]},{"cell_type":"code","metadata":{"id":"shhViI-J5aE6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":167},"executionInfo":{"status":"ok","timestamp":1599152851778,"user_tz":240,"elapsed":40433,"user":{"displayName":"Nicholas Miller","photoUrl":"","userId":"10828150341597191663"}},"outputId":"973de58e-a4fe-4af0-a3b0-641f8ee7f697"},"source":["!python data/preprocess_triples.py\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-03 17:07:13,768 - root - INFO - shuffle and split data/source/ml1m/kg/kg.dat for 0.7 training, 0.1 validation and 0.2 testing!\n","2020-09-03 17:07:15,212 - root - INFO - Predefined vocab: use 34 relations in vocab!\n","2020-09-03 17:07:18,514 - root - INFO - Totally 796219 facts of 210460 entities from data/source/ml1m/kg/kg.dat!\n","2020-09-03 17:07:19,027 - root - INFO - Cut infrequent entities (<=10), remaining 584837 facts of 13154 entities and 20 relations!\n","2020-09-03 17:07:19,814 - root - INFO - Splitting of data into train/test/validation is done!\n","2020-09-03 17:07:20,879 - root - INFO - Filtering unseen entities and relations.\n","2020-09-03 17:07:21,193 - root - INFO - 13031 entities and 20 relations, where 409386 train, 58417 valid, and 116827 test!\n","2020-09-03 17:07:21,193 - root - INFO - Saving dictionaries and model files!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jXbJ1wp-DNJe","colab_type":"text"},"source":["# **Data Verification**"]},{"cell_type":"markdown","metadata":{"id":"rLhQmAwBzkoO","colab_type":"text"},"source":["## **Check Train and Test Similarity**"]},{"cell_type":"code","metadata":{"id":"n-FZ5rmrPYxm","colab_type":"code","colab":{}},"source":["def read_rating_triple(file_path, user2id, rating2id, item2id):\n","  triples = dict()\n","  with open(file_path) as fin:\n","    for line in fin:\n","      h, r, t = line.strip().split('\\t')\n","      if user2id[h] in triples.keys():\n","        temp_list = triples[user2id[h]]\n","        temp_list.append(item2id[t])\n","        triples[user2id[h]] = temp_list\n","      else:\n","        triples[user2id[h]] = [item2id[t]]\n","  return triples\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qGcwALFaPJVR","colab_type":"code","colab":{}},"source":["# open rating dictionaries \n","with open('data/preprocess/ml1m/rating/user.dict') as fin:\n","  user2id = dict()\n","  for line in fin:\n","    uid, user = line.strip().split('\\t')\n","    user2id[user] = int(uid)\n","with open('data/preprocess/ml1m/rating/rating.dict') as fin:\n","  rating2id = dict()\n","  for line in fin:\n","    rid, rating = line.strip().split('\\t')\n","    rating2id[rating] = int(rid)\n","with open('data/preprocess/ml1m/rating/item.dict') as fin:\n","  item2id = dict()\n","  for line in fin:\n","    iid, item = line.strip().split('\\t')\n","    item2id[item] = int(iid)\n","\n","# load rating triples \n","ratings_train_triples = read_rating_triple('data/preprocess/ml1m/rating/train.txt', user2id, rating2id, item2id)\n","ratings_test_triples = read_rating_triple('data/preprocess/ml1m/rating/test.txt', user2id, rating2id, item2id)\n","\n","# calculate intersection\n","inter = 0\n","for u_train_key, m_train_value in ratings_train_triples.items():\n","  m_test_value = ratings_test_triples[u_train_key]\n","  for train_movie in m_train_value:\n","    for test_movie in m_test_value:\n","      if train_movie == test_movie:\n","        inter+=1\n","\n","# print results \n","print('Intersection: ', inter) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WsYAaTcWydUQ","colab_type":"code","colab":{}},"source":["ratings_train_triples = read_rating_triple('data/preprocess/ml1m/rating/train.txt', user2id, rating2id, item2id)\n","ratings_test_triples = read_rating_triple('data/preprocess/ml1m/rating/test.txt', user2id, rating2id, item2id)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PX-g8bY50z7Z","colab_type":"code","colab":{}},"source":["for u_train_key, m_train_value in ratings_train_triples.items():\n","  if u_train_key not in ratings_test_triples.keys():\n","    continue\n","  m_test_value = ratings_test_triples[u_train_key]\n","  for movie in m_test_value:\n","    m_train_value.append(movie)\n","  ratings_train_triples[u_train_key] = m_train_value"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTHxivDgyoRU","colab_type":"code","colab":{}},"source":["movie_counts = dict()\n","for u_train_key, m_train_value in ratings_train_triples.items():\n","  for movie in m_train_value:\n","    if movie in movie_counts.keys():\n","      movie_counts[movie] = movie_counts[movie] + 1\n","    else:\n","      movie_counts[movie] = 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TIfh1ZCjzB8O","colab_type":"code","colab":{}},"source":["{k: v for k, v in sorted(movie_counts.items(), key=lambda item: item[1], reverse=False)}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lV8kuvEJDaUT","colab_type":"text"},"source":["## **Random Test Set**"]},{"cell_type":"code","metadata":{"id":"JoyDtzPbZyZz","colab_type":"code","colab":{}},"source":["def read_triples(file_path):\n","  users = set()\n","  ratings = set()\n","  movies = set()\n","  with open(file_path) as fin:\n","    for line in fin:\n","      h, r, t = line.strip().split('\\t')\n","      users.add(h)\n","      ratings.add(r)\n","      movies.add(t)\n","  return users, ratings, movies\n","\n","def create_random_data_files(users, movies):\n","  train = list() # 70%\n","  valid = list() # 10%\n","  test = list() # 20%\n","  for user in users:\n","    randomlist = random.sample(range(len(movies)), 100)\n","    valid_list = randomlist[:10]\n","    test_list = randomlist[10:30]\n","    train_list = randomlist[30:]\n","\n","    for idx in valid_list:\n","      valid.append((user, 'has_watched', movies[idx]))\n","    for idx in test_list:\n","      test.append((user, 'has_watched', movies[idx]))\n","    for idx in train_list:\n","      train.append((user, 'has_watched', movies[idx]))\n","  return train, valid, test\n","\n","def write_files(file_name, data):\n","  with open(file_name, 'w', encoding='utf-8') as fout:\n","    for triple in data:\n","      fout.write('{}\\t{}\\t{}\\n'.format(triple[0], triple[1], triple[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qz39nQD6Z3k-","colab_type":"code","colab":{}},"source":["users, ratings, movies = read_triples('data/preprocess/ml1m/rating/train.txt')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sGmiBtPaYAq","colab_type":"code","colab":{}},"source":["a, b, c = create_random_data_files(list(users), list(movies))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UcT_AtO3c0PV","colab_type":"code","colab":{}},"source":["write_files('data/preprocess/ml1m/rating/train.txt', a)\n","write_files('data/preprocess/ml1m/rating/valid.txt', b)\n","write_files('data/preprocess/ml1m/rating/test.txt', c)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ICBWbWdeRUn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1599581267466,"user_tz":240,"elapsed":569,"user":{"displayName":"Nicholas Miller","photoUrl":"","userId":"10828150341597191663"}},"outputId":"1e143d8d-28e1-4ee1-b7bc-1dccb12f9a58"},"source":["len(a)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["422800"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"11SDap2EC-ML","colab_type":"text"},"source":["# **Models**"]},{"cell_type":"markdown","metadata":{"id":"oBwA3VAv1hhi","colab_type":"text"},"source":["## **rTransUp**"]},{"cell_type":"code","metadata":{"id":"UZlczHQOGWSF","colab_type":"code","colab":{}},"source":["!CUDA_VISIBLE_DEVICES=0 python rTransUP/run.py --do_train \\\n"," --cuda --do_valid --do_test \\\n"," --data_path data/preprocess/ml1m/ \\\n"," -n 64 -b 1024 -d 128 -g 12.0 \\\n"," -a 1.0 -adv -lr 0.001 \\\n"," --max_steps 150000 --valid_steps 15000 \\\n"," -save rTransUP/models/test --test_batch_size 16"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sSuxBna9TgZ8","colab_type":"code","colab":{}},"source":["!CUDA_VISIBLE_DEVICES=0 python rTransUP2/run.py --do_test --cuda -init rTransUP2/models/test\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s40cwKES1h0E","colab_type":"text"},"source":["## **Random**"]},{"cell_type":"code","metadata":{"id":"q9I9ReW11h7U","colab_type":"code","colab":{}},"source":["with open(os.path.join('data/preprocess/ml1m/rating/item.dict')) as fin:\n","  movie2id = dict()\n","  movies = list()\n","  for line in fin:\n","    id, movie = line.strip().split('\\t')\n","    movie2id[movie] = int(id)\n","    movies.append(int(id))\n","fin.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dfB5YBi1zRfs","colab_type":"code","colab":{}},"source":["# \"Test\" portion \n","test_batch = []\n","with open('data/preprocess/ml1m/rating/test.txt', 'r', encoding='utf-8') as fin:\n","  for line in fin:\n","    triple = line.strip().split('\\t')\n","    test_batch.append(movie2id[triple[2]])\n","fin.close()\n","\n","logs = []\n","high_rank = len(movies)\n","for movie in test_batch:\n","  # Notice that argsort is not ranking\n","  ranking = torch.randint(0, high_rank, (1,)).item() + 1\n","  logs.append({\n","    'MRR': 1.0 / ranking,\n","    'MR': float(ranking),\n","    'HITS@1': 1.0 if ranking <= 1 else 0.0,\n","    'HITS@3': 1.0 if ranking <= 3 else 0.0,\n","    'HITS@10': 1.0 if ranking <= 10 else 0.0,\n","    'HITS@25': 1.0 if ranking <= 25 else 0.0,\n","    'HITS@50': 1.0 if ranking <= 50 else 0.0,\n","    'HITS@100': 1.0 if ranking <= 100 else 0.0,\n","    'HITS@250': 1.0 if ranking <= 250 else 0.0,\n","  })        \n","        \n","metrics = {}\n","for metric in logs[0].keys():\n","  metrics[metric] = sum([log[metric] for log in logs]) / len(logs)\n","\n","for metric in metrics:\n","  print('%s: %f' % (metric, metrics[metric]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UeO_0KA01om3","colab_type":"text"},"source":["## **Most Popular**"]},{"cell_type":"code","metadata":{"id":"IdX1jGhMiP64","colab_type":"code","colab":{}},"source":["# \"Train\" portion \n","with open(os.path.join('data/preprocess/ml1m/rating/item.dict')) as fin:\n","  movie2id = dict()\n","  for line in fin:\n","    id, movie = line.strip().split('\\t')\n","    movie2id[movie] = int(id)\n","fin.close()\n","\n","movie_counts = dict()\n","with open('data/preprocess/ml1m/rating/train.txt', 'r', encoding='utf-8') as fin:\n","  for line in fin:\n","    triple = line.strip().split('\\t')\n","    triple_id = movie2id[triple[2]]\n","    movie_counts[triple_id] = movie_counts[triple_id] + 1 if triple_id in movie_counts.keys() else 1\n","fin.close()\n","\n","sorted_movie_counts = [(k, v) for k, v in sorted(movie_counts.items(), key=lambda item: item[1], reverse=True)]\n","ranked_movies = [(k[0], len(sorted_movie_counts) - i) for i, k in enumerate(sorted_movie_counts)]\n","most_popular_movies = [v for k, v in sorted(ranked_movies, key=lambda item: item[0])]\n","most_popular = torch.tensor(most_popular_movies).cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8EIg4BjrrxA","colab_type":"code","colab":{}},"source":["# \"Test\" portion \n","test_batch = []\n","with open('data/preprocess/ml1m/rating/test.txt', 'r', encoding='utf-8') as fin:\n","  for line in fin:\n","    triple = line.strip().split('\\t')\n","    test_batch.append(movie2id[triple[2]])\n","fin.close()\n","\n","logs = []\n","for movie in test_batch:\n","  # Notice that argsort is not ranking\n","  if (movie > 3205):\n","    continue\n","  ranking = most_popular[movie].item()\n","  logs.append({\n","    'MRR': 1.0 / ranking,\n","    'MR': float(ranking),\n","    'HITS@1': 1.0 if ranking <= 1 else 0.0,\n","    'HITS@3': 1.0 if ranking <= 3 else 0.0,\n","    'HITS@10': 1.0 if ranking <= 10 else 0.0,\n","    'HITS@25': 1.0 if ranking <= 25 else 0.0,\n","    'HITS@50': 1.0 if ranking <= 50 else 0.0,\n","    'HITS@100': 1.0 if ranking <= 100 else 0.0,\n","    'HITS@250': 1.0 if ranking <= 250 else 0.0,\n","  })        \n","        \n","metrics = {}\n","for metric in logs[0].keys():\n","  metrics[metric] = sum([log[metric] for log in logs]) / len(logs)\n","\n","for metric in metrics:\n","  print('%s: %f' % (metric, metrics[metric]))"],"execution_count":null,"outputs":[]}]}